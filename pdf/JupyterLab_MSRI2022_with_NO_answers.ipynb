{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uniform-bacon",
   "metadata": {},
   "source": [
    "# Lab: Parameter Estimation and Likehihood\n",
    "### Jessica Conrad, MSPH\n",
    "### MSRI Summer School on Algebraic Geometry July 2022 (Part 1)\n",
    "\n",
    "#### Based off of the Parameter Estimation Lab by Dr. Marisa Eisenberg found [here](https://epimath.org/epid-814-materials/Labs/EstimationLab/)\n",
    "\n",
    "# Part 1: Deterministic SIR Model Review\n",
    "The SIR model as we know it today was first formalized by Kermack and McKendrick in 1927. This mass-action compartmental model aims to predict the transmission of disease through a susceptible population over time. While the original model was a partial differential equaiton system tracking age-of-infection, we will explore here the simplified model that is only a function of time.\n",
    "\n",
    "The basic model is as follows:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dS}{dt} & = -\\beta SI \\\\\n",
    "\\frac{dI}{dt} & = \\beta SI - \\gamma I \\\\\n",
    "\\frac{dR}{dt} & = \\gamma I,\n",
    "\\end{align}\n",
    "$$\n",
    "where *t* is time, *S(t)* is susceptible people, *I(t)* is infected people, and *R(t)* is removed (aka recovered and/or dead) people. *$\\beta$* is the infection rate, and *$\\gamma$* is the recovery rate.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Usually, S + I + R = N implies a constant population. Our model assumes no birth or death explicitly.\n",
    "</div>\n",
    "\n",
    "<!---\n",
    "For this model, we can define the basic reproductive number, $\\mathcal{R}_0$:\n",
    "$$\n",
    "\\mathcal{R}_0 = \\frac{\\beta}{\\gamma},\n",
    "$$\n",
    "where we can consider $\\frac{1}{\\gamma}$ as the average time spent in the infectious compartment *I(t)*. As such, $\\mathcal{R}_0$ is the average number of secondary infections from the introduction of a single infectious case into a completely susceptible population. $\\mathcal{R}_0$ can be used as a rough estimate of the risk of an outbreak: if $\\mathcal{R}_0 > 1$, we expect an epidemic to grow; else if $\\mathcal{R}_0 < 1$, we expect the epidemic to die out.\n",
    "-->\n",
    "\n",
    "To summarize, our important variables and definitions are:\n",
    "* **S(t)** : susceptible population at time *t*\n",
    "* **I(t)** : infected population at time *t*\n",
    "* **R(t)** : removed population at time *t*\n",
    "* __$\\beta$__ : infection rate; expected number of secondary infections per time *t*\n",
    "* __$\\gamma$__ : recovery rate; $\\frac{1}{\\gamma}$ is average time a person is infectious/infected\n",
    "<!--- * __$\\mathcal{R}_0$__ : average number of secondary infections from one person per time *t* -->\n",
    "\n",
    "<!---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> $\\mathcal{R}_0$ as we have defined it above is only valid for a short time at the initialization of the epidemic. The effective reproductive number $\\mathcal{R}_t$ should be used for risk calculations after time $t=0$. This can be approximated as $\\mathcal{R}_t= \\mathcal{R}_0 \\frac{S(t)}{N} = \\frac{\\beta}{\\gamma} \\frac{S(t)}{N}$.\n",
    "</div>\n",
    "-->\n",
    "\n",
    "### Optional Resources\n",
    "If you have never coded in Python before, the following short tutorials are recommended:\n",
    "* [10 minute Python Tutorial](https://www.stavros.io/tutorials/python/) Short tutorial with the basics recommended if you have done coding before in Python, but maybe not in a while\n",
    "* [Official Python Tutorial](https://docs.python.org/3/tutorial/) Official Python tutorial with details and references. Good if you have never coded in Python before.\n",
    "* [Think Python](https://greenteapress.com/wp/think-python-2e/) In depth introduction to Python coding\n",
    "\n",
    "### Coding the deterministic SIR Model\n",
    "Now let's review how to code the deterministic SIR Model in Python. We will write this code together, step by step, then put it together! After we have learned how to write the model in Python, we will then build our likelihood function code.\n",
    "\n",
    "First, we will import the libraries we will need for this code. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Python Hint:</b> What are libraries and how do we use them? Libraries contain bundles of code created by other users, including useful functions, object classes, and data presets. Using the *import* command, we can access libraries instead of reinventing the wheel. Using the *from* command, we can access specific functions from a library.\n",
    "\n",
    "Some libraries are commonly referred to by a name other than their official name. For example, *scipy.stats* is often just called *stats*. Below you will see this name reference specified with the <b>as</b> command.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Python Hint:</b> When using a Jupyter notebook, you need to run coding blocks in the order they are presented. If you run the blocks out of order, often errors will be generated. Click on the block below such that it is highlighted by a green outline. Then in the upper left corner of this notebook, click \"Run.\"\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "simplified-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The libraries have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "from math import *                         # useful math functions\n",
    "import numpy as np                         # useful array objects \n",
    "                                           # (also a core scientific computing library)\n",
    "\n",
    "import scipy.stats as stats                #useful statistics functions\n",
    "import copy                                #allows for deep copies of objects\n",
    "\n",
    "print(\"The libraries have been downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-activation",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Python Hint:</b> What is a comment? You might have noticed some lines in the code above that are all in green. When writing in Python, you can comment code by putting a \"#\" before the character string. This tells the compiler to ignore the characters that follow <i>until you reach the next line of code</i>. Please comment your code always with notes for what a block of code is supposed to do! This is excellent coding practice called \"Annotating\".\n",
    "</div>\n",
    "\n",
    "Now let's try defining functions for movement between compartments! The functions have been written for you. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Python Hint:</b> What is a function? Generally speaking a function is a block of code that only runs when called. In Python, we indicate that a function is about to be defined using the *def* command. The general form for defining a function in Python is: <b>def</b> myfuncname(inputs): ...\n",
    "    \n",
    "Once a command is defined, you can call it using something like: myfuncname(inputs). We will show how to use this soon!\n",
    "</div>\n",
    "\n",
    "### Fill in the state equations below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "premium-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model equations for the scaled SIR model for python 2.7\n",
    "# Original authors of this code, before edits by J. Conrad:\n",
    "# Marisa Eisenberg (marisae@umich.edu)\n",
    "# Yu-Han Kao (kaoyh@umich.edu) -7-9-17\n",
    "\n",
    "def model(ini, time_step, params):\n",
    "    #Define our ODE model\n",
    "    \n",
    "    ###########################\n",
    "    #Input:\n",
    "    #   ini           initial inputs for the state variables S, I, R\n",
    "    #   time_step     time step definition; used by the ODE wrapper\n",
    "    #   params        parameters for this model, in this case beta and gamma\n",
    "    #\n",
    "    #Output:\n",
    "    #   Y             vector of state variable equations for S, I, and R\n",
    "    ###########################\n",
    "\tY = np.zeros(3)       #column vector for the state variables S, I, and R\n",
    "\tX = ini               #our initial conditions as defined from the input, also a column vector of our state vars\n",
    "\tbeta = params[0]\n",
    "\tgamma = params[1]\n",
    "\n",
    "\n",
    "### FILL IN THIS SECTION with your equations as defined above! Note that in python, S = X[0], I = X[1], and R = X[2]\n",
    "\tY[0] = ...\n",
    "\tY[1] = ...\n",
    "\tY[2] = ...\n",
    "\n",
    "\treturn Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-arrow",
   "metadata": {},
   "source": [
    "# Part 2: Some Real Life Drama\n",
    "\n",
    "Our basic model might be a little too basic. The researchers at the State Health Department have requested that you include birth and death of the population in your model. How do we reframe our original model to include birth and death, while maintaining the rule that S + I + R = N?\n",
    "\n",
    "### Write your model in the markdown section that follows here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-escape",
   "metadata": {},
   "source": [
    "The basic model was:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dS}{dt} & = -\\beta SI \\\\           %When we use \"\\$\\$\" around a block of code in Markdown, we switch to Latex\n",
    "\\frac{dI}{dt} & = \\beta SI - \\gamma I \\\\ %coding language, which is nice for inputing equations and math :)\n",
    "\\frac{dR}{dt} & = \\gamma I,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "My new model is:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dS}{dt} & = \\mu N -\\beta SI - \\mu S\\\\     %(****remove for sandbox version of code****)\n",
    "\\frac{dI}{dt} & = \\beta SI - \\gamma I -\\mu I \\\\ %(****remove for sandbox version of code****)\n",
    "\\frac{dR}{dt} & = \\gamma I - \\mu R,             %(****remove for sandbox version of code****)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-congo",
   "metadata": {},
   "source": [
    "Oh no. The official from the department has notified you that even though they have been doing their best to identify all infectious cases, reporting isn't perfect. The data they recieve from hospitals and clinics represents only a fraction of all true cases.\n",
    "\n",
    "As such, we will define now an output variable $y(t)$ which represents the number of reported infectious cases:\n",
    "$$\n",
    "y = k I\n",
    "$$\n",
    "where $k$ is the reporting rate. This is also known as our measurement equation. \n",
    "\n",
    " <br/><br/>\n",
    "\n",
    "Oh wow! We have some new parameters, and now a defined output. Can you solve for the structural identifiability by hand? \n",
    "\n",
    "### Write the input-output equation for your new model below and discuss the structural identifiability of the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-contract",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qualified-shooting",
   "metadata": {},
   "source": [
    "### What happens if we rescale the model in terms of \"fraction of the population\"? \n",
    "How does this change the identifiability of the model? Make sure to include in the markdown section below the definition of all your new equations, including how to redefine the output equation. For consistency, let $\\kappa = k*N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-domestic",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-trick",
   "metadata": {},
   "source": [
    "Ok, so how can we redefine the model function to include our new parameter(s)? \n",
    "\n",
    "### Redefine _model_() by adding your new terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "uniform-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(ini, time_step, params):\n",
    "\tY = np.zeros(3) #column vector for the state variables\n",
    "\tX = ini\n",
    "\tmu = 0\n",
    "\tbeta = params[0]\n",
    "\tgamma = params[1]\n",
    "\n",
    "\tY[0] = ...\n",
    "\tY[1] = ...\n",
    "\tY[2] = ...\n",
    "\n",
    "\treturn Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-arena",
   "metadata": {},
   "source": [
    "The health department doesn't want to give us their HIPPA protected patient data right away. We need to prove to them that our model will work as expected. So first things first: if we had data with errors, would it return back to us a known parameter set that we decided on? How do we test this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-consent",
   "metadata": {},
   "source": [
    "# Part 3: Data Simulation\n",
    "\n",
    "We are at a cross roads, where now we need to generate some fake data. For this section, we will begin by assuming the birth and death rates are slow enough to assume $\\mu = 0$. This assumption is only valid for fast acting diseases.\n",
    "As such, let's define our \"true\" parameter set such that $\\beta = 0.4$, $\\gamma = 0.25$, and $\\kappa = 80000.$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Why is the assumption $\\mu = 0$ valid here? Consider the timescale of our flowrates. If $\\gamma$ is the recovery rate, then the average time spent infected is $1/\\gamma \\approx 4$ days. Generally, we consider birth and death rates when the scale of the epidemic extends across many months or years. For the purpose of this simulation and simplicity, we do not need to consider birth/death at this time.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> I thought $\\kappa$ was the reporting rate! Why is it greater than 1? Recall that due to our rescaling, we defined $\\kappa  = k*N$ where $k$ is the reporting rate given total population $N$.\n",
    "</div>\n",
    "\n",
    "\n",
    "Next, I'm going to give us a break and define some pre-generated test data with noise. Run the following block of code to generate our \"true\" data and new parameter definition!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "laden-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data ####\n",
    "times = [0, 7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91, 98]\n",
    "data = [97, 271, 860, 1995, 4419, 6549, 6321, 4763, 2571, 1385, 615, 302, 159, 72, 34]\n",
    "\n",
    "#DEFINE THE PARAMETER SET\n",
    "#(****remove for sandbox version of code****)\n",
    "params = [0.4, 0.25, 80000.0]        #make sure all the params and inition states are float\n",
    "paramnames = ['beta', 'gamma', 'k']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-massage",
   "metadata": {},
   "source": [
    "For the initial conditions of our ODE, we are going to use:\n",
    "$$\n",
    "\\begin{align}\n",
    "S(0) & = 1 - I(0) \\\\\n",
    "I(0) & = data(0)/\\kappa\\\\\n",
    "R(0) & = 0,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $data(0)$ is the first data value recorded. Note that the initial conditions depend on both the data and our parameter values! I often like to make the initial conditions a function, so that if we ever want to change the initial condition set up, we can just change the function definition and everything else will update automatically.\n",
    "As such, we define the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "military-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x0fcn(params, data):\n",
    "    #Set initial conditions\n",
    "    \n",
    "    ###########################\n",
    "    #Input:\n",
    "    #   data          true data to be fit\n",
    "    #   params        parameters for this mode, in this case beta, gamma, and kappainv\n",
    "    #\n",
    "    #Output:\n",
    "    #   X0            initial conditions for the SIR ODE          \n",
    "    ###########################\n",
    "\tS0 = ...\n",
    "\tI0 = ...\n",
    "\tR0 = ...\n",
    "\tX0 = [S0, I0, R0]\n",
    "\n",
    "\treturn X0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-cuisine",
   "metadata": {},
   "source": [
    "Ok let's try using this function now! \n",
    "### Write the Python code below that will generate and print a new object called \"ini\", our initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-lodging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "passing-revolution",
   "metadata": {},
   "source": [
    "We have the model equations in our function above, but the last thing we need to simulate the model is the measurement equation -- this defines what variables of the model we are observing. We’ll make this a function too, so that way it’s easy to update the code if we decide to measure something else. We’ll make our measurement equation yfun take two inputs: the model simulation results (call this *res*) and the parameters (we’ll call this *params*). Recall that we defined our measurement (or output) equation as $y = \\kappa I$.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Python Hint:</b> We know that our output data from the ODE should be returned as an object called \"res\" with 3 columns. In Python, when referencing a row or column, the indexing starts at 0. So if we want to recall the second column of the \"res\" object, we need to write res[:,1].\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sought-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yfcn(res, params):\n",
    "    #Define measurement equation\n",
    "    \n",
    "    ###########################\n",
    "    #Input:\n",
    "    #   res           simulated data results\n",
    "    #   params        parameters for this mode, in this case beta, gamma, and kappainv\n",
    "    #\n",
    "    #Output:\n",
    "    #   simulated reported data \n",
    "    ###########################\n",
    "\treturn ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-blond",
   "metadata": {},
   "source": [
    "Now it's time to put all the pieces together and plot simulated data from our model against the true data I gave you. We need an ODE solver to take our model definition and parameters and generate \"res\". Instead of writing our own ODE solver, we can call one from a library! See how this is done below using the `from` command.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Python Hint:</b> How did she know what inputs to give the ODE command? Either it's witchcraft...or it's Google! Try googling \"scipy library odeint function\". You should see a link for \"SciPy v1.8.1 Manual\" pop up! If not, see the documentation <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\">here</a> . The documentation in this link will tell you in what order and what type of input objects can be used.\n",
    "\n",
    "The type of object you input into a function is <i>very</i> important. Often, when a function throws an error, the user input the wrong object type. For documentation inline while coding, you can alternatively run the line <b>help(ode)</b> instead of Googling.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint as ode  # ode solver\n",
    "\n",
    "#### Simulate the model ####\n",
    "res = ode(model, ini, times, args=(params,))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-status",
   "metadata": {},
   "source": [
    "So we have our model output data, and the true data! Except our true data was subject to a reporting bias :( \n",
    "\n",
    "...good thing we made that measurement functin yfcn() to correct for this! \n",
    "### Define a new object called \"sim_measure\", our simulation predicted output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-louisiana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "decreased-junior",
   "metadata": {},
   "source": [
    "Now put it all together. I've given you the code below to plot your simulation and true data together. Just click run and see what you get!\n",
    "\n",
    "### Annotate the code below so you know what it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt            # nice plotting commands, very similar to Matlab commands\n",
    "\n",
    "\n",
    "plt.plot(times, sim_measure, 'b-', linewidth=3, label='Model simulation')\n",
    "plt.plot(times, data, 'ko', linewidth=2, label='Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Individuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-republic",
   "metadata": {},
   "source": [
    "# Part 4: Numerical Identifiability Checks using Profile Likelihood\n",
    "\n",
    "Wow we made it pretty far into our analysis. But now we want to know if the proposed parameter set is unique, or rather, identifiable from the data. We have already investigated the structural identifiability of this model, and now we want to explore the practical identifiability. That is, <b>can we recover the original parameter set when given ouput data with noise?</b>\n",
    "    \n",
    "To do this, we are going to use the Poisson maximum likelihood function that we derived together earlier! Remember that we re-framed the MLE as instead minimizing the negative log likelihood to simplify our algorithm.\n",
    "\n",
    "Next, we will write code to estimate $\\beta, \\gamma$, and $\\kappa$ from the given data using Poisson maximum likelihood. Use the parameter values given above as starting parameter values, and you can use the initial conditions from above as well (note though that they depend on $\\kappa$, which is a fitted parameter—so while we aren’t fitting the initial conditions, they will need to change/update as we fit the parameters!). This means you will need to update your initial conditions inside the cost function, so Python uses the updated initial conditions when it tries new parameter values. \n",
    "\n",
    "For note taking purposes, in the box below use the `sum` function to fill in the missing line.\n",
    "### Record here the Poisson likelihood function in Markdown, then fill in the Python block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-round",
   "metadata": {},
   "source": [
    "The Poisson maximum likelihood function, reframed for minimizing the negative log likelihood is:\n",
    "$$\n",
    "min_{p} (-LL)  = ...\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "consistent-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm\n",
    "\n",
    "def NLL(params, data, times): \n",
    "    #Define the negative log likelihood\n",
    "    \n",
    "    ###########################\n",
    "    #Input:\n",
    "    #   params        parameters for this mode, in this case beta, gamma, and kappainv\n",
    "    #   data          true data to be fit\n",
    "    #   times         time points when the true data is recorded\n",
    "    #\n",
    "    #Output:\n",
    "    #   nll           negative log likelihood estimate    \n",
    "    ###########################\n",
    "\tparams = np.abs(params)\n",
    "\tdata = np.array(data)\n",
    "    \n",
    "    #Simulate the model with current parameters\n",
    "\tres = ode(model, x0fcn(params,data), times, args=(params,))\n",
    "    \n",
    "    #Apply the measurement equation\n",
    "\ty = yfcn(res, params)\n",
    "    \n",
    "    #Calculate the NLL for Poisson distribution\n",
    "\tnll = ...\n",
    "    \n",
    "\t# note this is a slightly shortened version--there's an additive constant term missing but it \n",
    "\t# makes calculation faster and won't alter the threshold. Alternatively, can do:\n",
    "\t# nll = -sum(np.log(poisson.pmf(np.round(data),np.round(y)))) # the round is b/c Poisson is for (integer) count \n",
    "\t# data this can also barf if data and y are too far apart because the dpois will be ~0, which makes the log \n",
    "    # angry\n",
    "\t\n",
    "\t# ML using normally distributed measurement error (least squares)\n",
    "\t# nll = -sum(np.log(norm.pdf(data,y,0.1*np.mean(data)))) # example WLS assuming sigma = 0.1*mean(data)\n",
    "\t# nll = sum((y - data)**2)  # alternatively can do OLS but note this will mess with the thresholds \n",
    "\t#                             for the profile! This version of OLS is off by a scaling factor from\n",
    "\t#                             actual LL units.\n",
    "\treturn nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-cylinder",
   "metadata": {},
   "source": [
    "### Estimate the parameters using `optimize`. \n",
    "Armed with our likelihood function, we can now estimate the model parameters from the data. We will define a new object called \"paramests\" to save our parameter estimates in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "color-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as optimize          #optimizer function package\n",
    "\n",
    "optimizer = optimize.minimize(NLL, params, args=(data, times), method='Nelder-Mead')\n",
    "paramests = np.abs(optimizer.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-lodging",
   "metadata": {},
   "source": [
    "Finally, let’s put the data together with our model using the parameter estimates we found. First we have to re-simulate the model using the parameter estimate values, otherwise we just have parameter estimates but no way to see what the fit looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Re-generate initial case data based on new parameter estimates\n",
    "iniests = ...\n",
    "\n",
    "#### Re-simulate and plot the model with the final parameter estimates ####\n",
    "#Simulate data\n",
    "xest = ...\n",
    "#Apply the measurement equation\n",
    "est_measure = ...\n",
    "\n",
    "#Plot\n",
    "plt.plot(times, est_measure, 'b-', linewidth=3, label='Model simulation')\n",
    "plt.plot(times, data, 'ko', linewidth=2, label='Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Individuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-attendance",
   "metadata": {},
   "source": [
    "Hold the phone! We fit our data, but with what? Take a look at your parameter estimates -- do they seem reasonable? How close to the initial values are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-digit",
   "metadata": {},
   "source": [
    "### Explore some likelihood functions\n",
    "\n",
    "Re-run your estimation code with some alternative likelihood functions, such as:\n",
    "* Normally distributed constant measurement error, i.e. ordinary least squares, $Cost= \\sum_i(data_i−y_i)^2$\n",
    "* Normally distributed measurement error dependent on the data, weighted least squares, e.g. using Poisson-style variance, $Cost= \\sum_i \\frac{(data_i−y_i)^2}{ data_i}$. This assumes the variance at any given data point is equal to the data ($\\sigma^2=data$), but you can also try other weightings! (Such as letting $\\sigma^2=data^2$.)\n",
    "* Extended/weighted least squares, e.g. also using Poisson-style variance, $Cost= \\sum_i \\frac{(data_i−y_i)^2}{y_i}$. This assumes the variance at the $i^{th}$ data point is equal to $y_i$, the model prediction at that time.\n",
    "* Maximum likelihood assuming other distributions for the observation error, e.g. negative binomial\n",
    "\n",
    "How do the parameter estimates and/or uncertainty differ from the estimates you got earlier? What are the underlying assumptions for on the model/measurement equation/likelihood that generate the different least squares cost functions given above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-wilderness",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-preparation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
